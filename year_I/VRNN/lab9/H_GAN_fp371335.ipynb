{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "H. GAN [student].ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "0TD5ZrvEMbhZ"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating Handwritten Digits with DCGAN"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ITZuApL56Mny"
      },
      "cell_type": "markdown",
      "source": [
        "Deep Convolutional Generative Adversarial Network ([DCGAN](https://arxiv.org/pdf/1511.06434.pdf))."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2MbKJY38Puy9"
      },
      "cell_type": "markdown",
      "source": [
        "## What are GANs?\n",
        "Generative Adversarial Networks (GANs) are a framework for estimating generative models. Two models are trained simultaneously by an adversarial process: a Generator, which is responsible for generating images, and a Discriminator, which is responsible for estimating the probability that an image was drawn from the training data (the image is real), or was produced by the Generator (the image is fake). During training, the Generator becomes progressively better at generating images, until the Discriminator is no longer able to distinguish real images from fake. \n",
        "\n",
        "![alt text](https://github.com/margaretmz/tensorflow/blob/margaret-dcgan/tensorflow/contrib/eager/python/examples/generative_examples/gans_diagram.png?raw=1)\n",
        "\n",
        "We will demonstrate this process end-to-end on MNIST. Below is an animation that shows a series of images produced by the Generator as it was trained for 50 epochs. Overtime, the generated images become increasingly difficult to distinguish from the training set.\n",
        "\n",
        "![sample output](https://tensorflow.org/images/gan/dcgan.gif)"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "e1_Y75QXJS6h"
      },
      "cell_type": "markdown",
      "source": [
        "### Import Keras"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YfIk2es3hJEd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import *\n",
        "from keras.optimizers import Adam\n",
        "from tqdm import tqdm\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "iYn4MdZnKCey"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the dataset\n",
        "\n",
        "We are going to use the MNIST dataset to train the generator and the discriminator. The generator will generate handwritten digits resembling the MNIST data."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "a4fYMGxGhrna",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(X_train, _), (_, _) = mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_train = (X_train - 127.5) / 127.5\n",
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "THY-sZMiQ4UV"
      },
      "cell_type": "markdown",
      "source": [
        "## Create the models\n",
        "\n",
        "The discriminator and the generator optimizers are different since we will train two networks separately."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-tEyxE-GMC48"
      },
      "cell_type": "markdown",
      "source": [
        "### The Generator Model\n",
        "\n",
        "The generator is responsible for creating convincing images that are good enough to fool the discriminator. The network architecture for the generator consists of Conv2DTranspose (Upsampling) layers. We start with a fully connected layer and upsample the image two times in order to reach the desired image size of 28x28x1. We increase the width and height, and reduce the depth as we move through the layers in the network. We use Leaky ReLU activation for each layer except for the last one where we use a tanh activation."
      ]
    },
    {
      "metadata": {
        "id": "6bpTcDqoLWjY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU())\n",
        "  \n",
        "  model.add(Reshape((7, 7, 256)))\n",
        "  assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
        "  \n",
        "  model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 7, 7, 128)  \n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU())\n",
        "  \n",
        "  model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 14, 14, 64)    \n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU())\n",
        "  \n",
        "  model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "  assert model.output_shape == (None, 28, 28, 1)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "D0IKnaCtg6WE"
      },
      "cell_type": "markdown",
      "source": [
        "### The Discriminator model\n",
        "\n",
        "The discriminator is responsible for distinguishing fake images from real images. It's similar to a regular CNN-based image classifier."
      ]
    },
    {
      "metadata": {
        "id": "dw2tPLmk2pEP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same',input_shape=(28,28,1)))\n",
        "  model.add(LeakyReLU())\n",
        "  model.add(Dropout(0.3))\n",
        "  \n",
        "  model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "  model.add(LeakyReLU())\n",
        "  model.add(Dropout(0.3))\n",
        "  \n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1))\n",
        "  model.add(Activation('sigmoid'))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Rw1fkAczTQYh"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up GANs for Training\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5QC5BABamh_c"
      },
      "cell_type": "markdown",
      "source": [
        "Now it's time to put together the generator and discriminator to set up the Generative Adversarial Networks, as you see in the diagam at the beginning of the tutorial.\n",
        "\n",
        "Get the output of the generator and then feed it to the discriminator ( D(G(input)) )."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NS2GWywBbAWo",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''TODO'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jylSonrqSWfi"
      },
      "cell_type": "markdown",
      "source": [
        "**Define training method**\n",
        "\n",
        "We start by iterating over the dataset. The generator is given a random vector as an input which is processed to output an image looking like a handwritten digit. The discriminator is then shown the real MNIST images as well as the generated images."
      ]
    },
    {
      "metadata": {
        "id": "3t5ibNo05jCB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epoch = '''TODO'''\n",
        "batch_size = '''TODO'''\n",
        "\n",
        "batch_count = X_train.shape[0] // batch_size\n",
        "\n",
        "for i in range(n_epoch):\n",
        "  for j in tqdm(range(batch_count)):\n",
        "    # Input for the generator\n",
        "    noise_input = np.random.rand(batch_size, 100)\n",
        "    \n",
        "    # getting random images from X_train of size=batch_size\n",
        "    # these are the real images that will be fed to the discriminator\n",
        "    image_batch = X_train[np.random.randint(0, X_train.shape[0], size=batch_size)]\n",
        "    \n",
        "    # these are the predicted images from the generator\n",
        "    predictions = generator.predict(noise_input, batch_size=batch_size)\n",
        "    \n",
        "    # the discriminator takes in the real images and the generated images\n",
        "    X = np.concatenate([predictions, image_batch])\n",
        "    \n",
        "    # labels for the discriminator\n",
        "    y_discriminator = [0]*batch_size + [1]*batch_size\n",
        "    \n",
        "    # Let's train the discriminator\n",
        "    discriminator.trainable = True\n",
        "    discriminator.train_on_batch(X, y_discriminator)\n",
        "    \n",
        "    # Let's train the generator\n",
        "    noise_input = np.random.rand(batch_size, 100)\n",
        "    y_generator = [1]*batch_size\n",
        "    discriminator.trainable = False\n",
        "    gan.train_on_batch(noise_input, y_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Up_VmCwYL9Tj"
      },
      "cell_type": "markdown",
      "source": [
        "## Generated images \n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "mLskt7EfXAjr"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "After training, its time to generate some images! \n",
        "The last step is to plot the generated images and voila!\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WfO5wCdclHGL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try_input = np.random.rand(100, 100)\n",
        "preds = generator.predict(try_input)\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(preds.shape[0]):\n",
        "  plt.subplot(10, 10, i+1)\n",
        "  plt.imshow(preds[i, :, :, 0], cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
