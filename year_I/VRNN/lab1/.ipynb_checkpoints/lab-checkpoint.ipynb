{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-10-10 18:57:33--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "Translacja www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
      "Łączenie się z www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... połączono.\n",
      "Żądanie HTTP wysłano, oczekiwanie na odpowiedź... 200 OK\n",
      "Długość: 170498071 (163M) [application/x-gzip]\n",
      "Zapis do: `cifar-10-python.tar.gz'\n",
      "\n",
      "cifar-10-python.tar 100%[===================>] 162,60M  5,50MB/s    w 2m 3s    \n",
      "\n",
      "2019-10-10 18:59:37 (1,32 MB/s) - zapisano `cifar-10-python.tar.gz' [170498071/170498071]\n",
      "\n",
      "cifar-10-batches-py/\n",
      "cifar-10-batches-py/data_batch_4\n",
      "cifar-10-batches-py/readme.html\n",
      "cifar-10-batches-py/test_batch\n",
      "cifar-10-batches-py/data_batch_3\n",
      "cifar-10-batches-py/batches.meta\n",
      "cifar-10-batches-py/data_batch_2\n",
      "cifar-10-batches-py/data_batch_5\n",
      "cifar-10-batches-py/data_batch_1\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "!rm -r cifar-10-batches-py\n",
    "!tar xvzf cifar-10-python.tar.gz\n",
    "!rm cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "train_data = np.empty((0,3072))\n",
    "train_labels = np.empty((0))\n",
    "CIFAR_TRAIN_DATA = []\n",
    "\n",
    "for i in range(1, 2):\n",
    "    with open('cifar-10-batches-py/data_batch_{}'.format(i), \"rb\") as f:\n",
    "        data = pickle.load(f, encoding=\"bytes\")\n",
    "        train_data = np.append(train_data, data[b'data'], axis=0)\n",
    "        train_labels = np.append(train_labels, data[b'labels'])\n",
    "        \n",
    "        for label, data in zip(train_labels, train_data):\n",
    "            CIFAR_TRAIN_DATA.append((data, label))\n",
    "\n",
    "test_data = np.empty((0,3072))\n",
    "test_labels = np.empty((0))\n",
    "CIFAR_TEST_DATA = []\n",
    "\n",
    "with open(\"cifar-10-batches-py/test_batch\", \"rb\") as f:\n",
    "    data = pickle.load(f, encoding=\"bytes\")\n",
    "    test_data = np.append(test_data, data[b'data'], axis=0)\n",
    "    test_labels = np.append(test_labels, data[b'labels'])\n",
    "    \n",
    "    for label, data in zip(test_labels, test_data):\n",
    "        CIFAR_TEST_DATA.append((data, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_l2(a, b):\n",
    "    return np.linalg.norm(a-b)\n",
    "\n",
    "def metric_l1(a, b):\n",
    "    return np.linalg.norm(a-b, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nsmallest\n",
    "from itertools import groupby, tee\n",
    "\n",
    "\n",
    "def label(t):\n",
    "    return t[1]\n",
    "\n",
    "\"\"\"Project grouping to suitable form, allowing easy extraction of the label: \n",
    "    (size of group, -min distance, label)\"\"\"\n",
    "def project_group(t):\n",
    "    # t[1] contains iterator with (distance, group)\n",
    "    min_it, len_it = tee(t[1], 2)\n",
    "    # (count of elems in group, negated minimum distance, label)\n",
    "    return (sum(1 for _ in len_it), -min(map(lambda v: v[0], min_it)), t[0])\n",
    "\n",
    "\"\"\"Gets label for nearest neighbour in train_data\"\"\"\n",
    "def nearest_neighbour_label(train_data, metric, target, k=1):\n",
    "    first_k = nsmallest(k, map(lambda n: (metric(n[0], target), n[1]), train_data ))\n",
    "    # then grouping by labels the result\n",
    "    first_k = sorted(first_k, key=label)\n",
    "    groups = groupby(first_k, key=label)\n",
    "    return max(map(project_group, groups))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP_STEP = 20\n",
    "\n",
    "\n",
    "def cifar_test_metric(metric, train_data, test_data, k=1):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for test_data_obj in test_data:\n",
    "        total += 1\n",
    "        if total % SKIP_STEP != 0:\n",
    "            continue\n",
    "        correct += (nearest_neighbour_label(train_data, metric, test_data_obj[0], k=k) == test_data_obj[1])\n",
    "            \n",
    "    return correct / total * SKIP_STEP * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def merge_chunks(chunks, i):\n",
    "    result = np.array([], dtype=np.int32)\n",
    "    \n",
    "    for j in range(len(chunks)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        result = np.append(result, chunks[j])\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "def cross_validation(data, split=4, k=1):\n",
    "    data = np.array(data)\n",
    "    indices = list(range(len(data)))\n",
    "    random.shuffle(indices)\n",
    "    chunks = np.array_split(np.array(indices), split)\n",
    "    chunks_len = len(chunks)\n",
    "    results = {\"l2\": [], \"l1\": []}\n",
    "    \n",
    "    for i in range(chunks_len):\n",
    "        test_data = data[list(chunks[i])]\n",
    "        train_data = data[merge_chunks(chunks, i)]\n",
    "        \n",
    "        results[\"l2\"].append(cifar_test_metric(metric_l2, train_data, test_data, k=k))\n",
    "        results[\"l1\"].append(cifar_test_metric(metric_l1, train_data, test_data, k=k))\n",
    "        \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done cross-validation for 1 nearest neighbours\n",
      "Done cross-validation for 3 nearest neighbours\n",
      "Done cross-validation for 5 nearest neighbours\n",
      "Done cross-validation for 7 nearest neighbours\n"
     ]
    }
   ],
   "source": [
    "CROSS_VALIDATE_K = [1, 3, 5, 7]\n",
    "ACCURACIES = {\"l1\": {}, \"l2\": {}}\n",
    "\n",
    "\n",
    "for k in CROSS_VALIDATE_K:\n",
    "    result = cross_validation(CIFAR_TRAIN_DATA, k=k)\n",
    "    print(f\"Done cross-validation for {k} nearest neighbours\")\n",
    "    \n",
    "    for m in (\"l1\", \"l2\"):\n",
    "        ACCURACIES[m][k] = {\"avg\": np.average(result[m]), \"res\": result[m]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for metric l1:\n",
      "\n",
      "k = 1, avg = 28.400000000000002\t: 29.6\t24.0\t32.0\t28.0\n",
      "k = 3, avg = 30.400000000000002\t: 35.2\t31.2\t25.6\t29.6\n",
      "k = 5, avg = 34.800000000000004\t: 40.0\t36.0\t32.8\t30.4\n",
      "k = 7, avg = 33.2\t: 37.6\t24.0\t26.4\t44.8\n",
      "\n",
      "Best k: 5\n",
      "\n",
      "\n",
      "Results for metric l2:\n",
      "\n",
      "k = 1, avg = 30.2\t: 33.6\t24.0\t33.6\t29.6\n",
      "k = 3, avg = 26.799999999999997\t: 24.0\t25.6\t24.0\t33.6\n",
      "k = 5, avg = 31.599999999999998\t: 33.6\t31.2\t30.4\t31.2\n",
      "k = 7, avg = 29.6\t: 28.8\t25.6\t22.4\t41.6\n",
      "\n",
      "Best k: 5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BEST_K = {}\n",
    "\n",
    "def print_results(results):\n",
    "    results_for_k = []\n",
    "    for k in results:\n",
    "        avg = results[k]['avg']\n",
    "        res = results[k]['res']\n",
    "        results_for_k.append((avg, k))\n",
    "        print(f\"k = {k}, avg = {avg}\\t: \" + \"\\t\".join(map(lambda f: str(round(f, 2)), res)))\n",
    "    best_k = max(results_for_k)[1]\n",
    "    print(\"\")\n",
    "    \n",
    "    print(f\"Best k: {best_k}\")\n",
    "    \n",
    "    return best_k\n",
    "    \n",
    "        \n",
    "for metric in ACCURACIES:\n",
    "    print(f\"Results for metric {metric}:\\n\")\n",
    "    BEST_K[metric] = print_results(ACCURACIES[metric])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L2: Selected k for k-NearestNeighbors = 5  accuracy = 29.6\n",
      "\n",
      "L1: Selected k for k-NearestNeighbors = 5  accuracy = 32.2\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nL2: Selected k for k-NearestNeighbors =\", BEST_K[\"l2\"], \" accuracy =\", round(cifar_test_metric(metric_l2, CIFAR_TRAIN_DATA, CIFAR_TEST_DATA, k=BEST_K[\"l2\"]), 3))\n",
    "\n",
    "\n",
    "print(\"\\nL1: Selected k for k-NearestNeighbors =\", BEST_K[\"l1\"], \" accuracy =\", round(cifar_test_metric(metric_l1, CIFAR_TRAIN_DATA, CIFAR_TEST_DATA, k=BEST_K[\"l1\"]), 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
